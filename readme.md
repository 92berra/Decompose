# í•œê¸€ ìƒì„± ëª¨ë¸ì˜ ì •í™•ë„ í–¥ìƒì„ ìœ„í•œ êµ¬ì„±ìš”ì†Œ ë¶„ë¦¬

<br/>
<br/>

## Introduction

í•œê¸€ì€ ì´ˆì„± 19ê°œ, ì¤‘ì„± 21ê°œ, ì¢…ì„± 28ê°œ(ì—†ìŒ í¬í•¨)ë¡œ ì¡°í•©í•˜ì—¬ ë§Œë“¤ ìˆ˜ ìˆëŠ” ì´ ê¸€ì ìˆ˜ëŠ” 11,172ì´ë‹¤. ì´ëŠ” í•œê¸€ í°íŠ¸ ë””ìì´ë„ˆê°€ ì§ì ‘ ì‘ì—…í•  ê²½ìš° ë§ì€ ì‹œê°„ê³¼ ë¹„ìš©ì´ ì†Œìš”ë˜ë¯€ë¡œ ë”¥ëŸ¬ë‹ì„ í†µí•´ í•´ê²°í•˜ê³ ì í•œë‹¤. ë¹ ë¥¸ ì†ë„ë¡œ ë°œì „í•˜ëŠ” ê¸°ìˆ ë¡œ ì¸í•´ ì„±ëŠ¥ê³¼ ì •í™•ë„ê°€ í–¥ìƒë˜ì—ˆìœ¼ë‚˜ ê·¸ í•œê³„ì ì€ ì—¬ì „íˆ ì¡´ì¬í•œë‹¤. ë”°ë¼ì„œ ë³¸ ë…¼ë¬¸ì€ í•œê¸€ êµ¬ì„±ìš”ì†Œì˜ ì¡°í•©ì„±ì— ì¤‘ì ì„ ë‘” ì‹¤í—˜ì„ ì„±ê³µì ìœ¼ë¡œ ë§ˆì³¤ìŒì— ë”°ë¼ ìœ„ì¹˜ ì •ë³´ë¥¼ ì´ìš©í•œ ë°ì´í„°ì…‹ì„ í†µí•´ í•œê¸€ ìƒì„± ëª¨ë¸ì˜ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ì¤‘ìš”í•œ ë°©í–¥ì„ ì œê³µí•˜ë©° í–¥í›„ í•œê¸€ ìƒì„± ì—°êµ¬ì— ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€í•œë‹¤.

<br/>

The total number of letters that can be created in Hangul by combining 19 initial consonants, 21 middle consonants, and 28 final consonants (including none) is 11,172. This is something that we want to solve through deep learning, as it takes a lot of time and money for Korean font designers to work on their own. Performance and accuracy have improved due to rapidly developing technology, but limitations still exist. Therefore, as this paper successfully completed an experiment focusing on the combinability of Hangul components, it provides important directions for improving the performance of Hangul generation models through a dataset using location information and is expected to contribute to future Hangul generation research do.

<br/>

#### 1) Overview
<img src='assets/1-introduction-overview.png'/>

<br/>

#### 2) Korean Components
<img src='assets/1-introduction-korean_components.png'/>

<br/>

#### 3) Korean Combination Type
<img src='assets/1-introduction-korean_combination_types.png'/>

<br>
<br>

## Prerequisites

ğŸ› ï¸ In Progress: Modify framework from Tensorflow to PyTorch 

* Ubuntu 22.04.3 LTS
* NVIDIA GeForce RTX 2080 Ti 
* Python 3.9.13
* Tensorflow-gpu 1.15

```
conda create --name decompose python=3.9.13
conda activate decompose
pip install -r requirements.txt
```

<br>
<br>

## Datasets

#### 1) Generate Korean Font Images

```
# change directory to datasets

# generate content images
python datasets/font2img.py --label_file datasets/characters/50characters.txt --font_dir datasets/fonts/source --output_dir datasets/images/source

# generate target images
python datasets/font2img.py --label_file datasets/characters/50characters.txt --font_dir datasets/fonts/target --output_dir datasets/images/target --start_idx 1
```

<br>

#### 2) Separate Components

<img src='assets/Separate_B.png'/>

```
python datasets/separator/separator-1type.py
python datasets/separator/separator-2type.py
python datasets/separator/separator-3type.py
python datasets/separator/separator-4type.py
python datasets/separator/separator-5type.py
python datasets/separator/separator-6type.py
```

<br/>

#### 3) Combine Separated Components for Training

```
python datasets/combine.py
```

<br/>

#### 4) Modify filename to sequential number for train

```
python datasets/name-modify.py
```

<br/>

#### 5) Transfer from images to tfrecords

```
python datasets/img2tfrecord.py 
```

<br/>
<br/>

## Train

```
python main.py --mode train --output_dir trained_model --max_epochs 500
```

<br/>
<br/>

## Test(Generate)

```
python main.py --mode test --output_dir result --checkpoint trained_model
```

<br/>
<br/>

## Result

<br/>

<b>1) Generated result sample</b>
<br/>
<div align='center'>
    <img src='assets/2-result-generated_sample_v2.png' width='700'/>
</div>

<br/>

<b>2) Generated result sample (unseen font style, seen characters)</b>
<br/>
<div align='center'>
    <img src='assets/2-result-generated_unseen_fontstyle.png' width='700'/>
</div>

<br/>

<b>3) Values of Loss, SSIM, FID </b>
<br/>
<div align='center'>
    <img src='assets/2-result-loss-ssim.png' width='500'/>
</div>

<br/>
<br/>
<br/>
<br/>
<br/>

<div align='center'>
    Copyright. 92berra 2024
</div>